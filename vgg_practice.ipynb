{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:03.599335Z","iopub.status.busy":"2022-09-28T07:10:03.597621Z","iopub.status.idle":"2022-09-28T07:10:03.635389Z","shell.execute_reply":"2022-09-28T07:10:03.634347Z","shell.execute_reply.started":"2022-09-28T07:10:03.599213Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:03.643867Z","iopub.status.busy":"2022-09-28T07:10:03.640494Z","iopub.status.idle":"2022-09-28T07:10:15.636354Z","shell.execute_reply":"2022-09-28T07:10:15.635276Z","shell.execute_reply.started":"2022-09-28T07:10:03.643823Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-28 07:10:09.184278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:09.285575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:09.286484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:09.288222: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-09-28 07:10:09.288538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:09.289255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:09.289866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:11.583962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:11.584752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:11.585431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-28 07:10:11.586039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 2s 0us/step\n","553476096/553467096 [==============================] - 2s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 244, 244, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 244, 244, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 244, 244, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 122, 122, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 122, 122, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 122, 122, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 61, 61, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 61, 61, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 61, 61, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 61, 61, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 30, 30, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 30, 30, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 30, 30, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 30, 30, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","\n","input_tensor = Input(shape=(244, 244, 3))\n","base_model = VGG16(input_tensor=input_tensor, include_top=True, weights='imagenet')\n","model = Model(inputs=input_tensor, outputs=base_model.output)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:15.641085Z","iopub.status.busy":"2022-09-28T07:10:15.640711Z","iopub.status.idle":"2022-09-28T07:10:15.816279Z","shell.execute_reply":"2022-09-28T07:10:15.815238Z","shell.execute_reply.started":"2022-09-28T07:10:15.641046Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","\n","def create_vggnet(in_shape=(224, 224, 3), n_classes=10):\n","  input_tensor = Input(shape=in_shape)\n","\n","  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_tensor)\n","  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","  x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","  x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","  x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","  x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","  x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","  x = GlobalAveragePooling2D()(x)\n","  x = Dropout(0.5)(x)\n","  x = Dense(units=120, activation='relu')(x)\n","  x = Dropout(0.5)(x)\n","\n","  output = Dense(units=n_classes, activation='softmax')(x)\n","\n","  model = Model(inputs=input_tensor, outputs=output)\n","  model.summary()\n","\n","  return model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:15.822517Z","iopub.status.busy":"2022-09-28T07:10:15.820178Z","iopub.status.idle":"2022-09-28T07:10:15.951837Z","shell.execute_reply":"2022-09-28T07:10:15.950764Z","shell.execute_reply.started":"2022-09-28T07:10:15.822481Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 512)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 120)               61560     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 120)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1210      \n","=================================================================\n","Total params: 14,777,458\n","Trainable params: 14,777,458\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = create_vggnet(in_shape=(224, 224, 3), n_classes=10)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:15.955127Z","iopub.status.busy":"2022-09-28T07:10:15.954237Z","iopub.status.idle":"2022-09-28T07:10:15.965274Z","shell.execute_reply":"2022-09-28T07:10:15.964111Z","shell.execute_reply.started":"2022-09-28T07:10:15.955076Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, GlobalAveragePooling2D, Input\n","from tensorflow.keras.models import Model\n","\n","def conv_block(tensor_in, filters, kernel_size, repeats=2, pool_strides=(2, 2), block_id=1):\n","  x = tensor_in\n","\n","  for i in range(repeats):\n","    conv_name = f'block{str(block_id)}_conv{str(i+1)}'\n","    x = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', name=conv_name)(x)\n","\n","  x = MaxPooling2D((2, 2), strides=pool_strides, name=f'block{str(block_id)}_pool')(x)\n","\n","  return x"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:15.967214Z","iopub.status.busy":"2022-09-28T07:10:15.966764Z","iopub.status.idle":"2022-09-28T07:10:16.007063Z","shell.execute_reply":"2022-09-28T07:10:16.005973Z","shell.execute_reply.started":"2022-09-28T07:10:15.967172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","test_input (InputLayer)      [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_conv3 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","=================================================================\n","Total params: 75,648\n","Trainable params: 75,648\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["input_tensor = Input(shape=(224, 224, 3), name='test_input')\n","x = conv_block(tensor_in=input_tensor, filters=64, kernel_size=(3, 3), repeats=3, pool_strides=(2, 2), block_id=1)\n","\n","conv_layers = Model(inputs=input_tensor, outputs=x)\n","conv_layers.summary()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:16.009045Z","iopub.status.busy":"2022-09-28T07:10:16.008647Z","iopub.status.idle":"2022-09-28T07:10:16.019233Z","shell.execute_reply":"2022-09-28T07:10:16.018252Z","shell.execute_reply.started":"2022-09-28T07:10:16.009007Z"},"trusted":true},"outputs":[],"source":["def create_vggnet_by_block(in_shape=(224, 224, 3), n_classes=10):\n","  input_tensor = Input(shape=in_shape, name='Input Tensor')\n","  x = conv_block(input_tensor, filters=64, kernel_size=(3, 3), repeats=2, pool_strides=(2, 2), block_id=1)\n","  x = conv_block(x, filters=128, kernel_size=(3, 3), repeats=2, pool_strides=(2, 2), block_id=2)\n","  x = conv_block(x, filters=256, kernel_size=(3, 3), repeats=3, pool_strides=(2, 2), block_id=3)\n","  x = conv_block(x, filters=512, kernel_size=(3, 3), repeats=3, pool_strides=(2, 2), block_id=4)\n","  x = conv_block(x, filters=512, kernel_size=(3, 3), repeats=3, pool_strides=(2, 2), block_id=5)\n","\n","  x = GlobalAveragePooling2D()(x)\n","  x = Dropout(0.5)(x)\n","  x = Dense(units=120, activation='relu')(x)\n","  x = Dropout(0.5)(x)\n","\n","  output = Dense(units=n_classes, activation='softmax')(x)\n","  \n","  model = Model(inputs=input_tensor, outputs=output, name='vgg_by_block')\n","  model.summary()\n","\n","  return model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:16.021367Z","iopub.status.busy":"2022-09-28T07:10:16.020949Z","iopub.status.idle":"2022-09-28T07:10:16.151542Z","shell.execute_reply":"2022-09-28T07:10:16.150447Z","shell.execute_reply.started":"2022-09-28T07:10:16.021322Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg_by_block\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input Tensor (InputLayer)    [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 120)               61560     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 120)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                1210      \n","=================================================================\n","Total params: 14,777,458\n","Trainable params: 14,777,458\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model =  create_vggnet_by_block(in_shape=(224, 224, 3), n_classes=10)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:16.153705Z","iopub.status.busy":"2022-09-28T07:10:16.153332Z","iopub.status.idle":"2022-09-28T07:10:16.158503Z","shell.execute_reply":"2022-09-28T07:10:16.157398Z","shell.execute_reply.started":"2022-09-28T07:10:16.153668Z"},"trusted":true},"outputs":[],"source":["IMAGE_SIZE = 128\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:16.162994Z","iopub.status.busy":"2022-09-28T07:10:16.162226Z","iopub.status.idle":"2022-09-28T07:10:16.610172Z","shell.execute_reply":"2022-09-28T07:10:16.609201Z","shell.execute_reply.started":"2022-09-28T07:10:16.162950Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import Sequence\n","import cv2\n","import sklearn\n","\n","def zero_one_scaler(image):\n","    return image/255.0\n","\n","def get_preprocessed_ohe(images, labels, pre_func=None):\n","    # preprocessing 함수가 입력되면 이를 이용하여 image array를 scaling 적용.\n","    if pre_func is not None:\n","        images = pre_func(images)\n","    # OHE 적용    \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","    \n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","    \n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n","\n","from tensorflow.keras.utils import Sequence\n","import cv2\n","import sklearn\n","\n","# 입력 인자 images_array labels는 모두 numpy array로 들어옴. \n","# 인자로 입력되는 images_array는 전체 32x32 image array임. \n","class CIFAR_Dataset(Sequence):\n","    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n","        '''\n","        파라미터 설명\n","        images_array: 원본 32x32 만큼의 image 배열값. \n","        labels: 해당 image의 label들\n","        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n","        augmentor: albumentations 객체\n","        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n","        '''\n","        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n","        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n","        self.images_array = images_array\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.augmentor = augmentor\n","        self.pre_func = pre_func\n","        # train data의 경우 \n","        self.shuffle = shuffle\n","        if self.shuffle:\n","            # 객체 생성시에 한번 데이터를 섞음. \n","            #self.on_epoch_end()\n","            pass\n","    \n","    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n","    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n","    def __len__(self):\n","        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n","        return int(np.ceil(len(self.labels) / self.batch_size))\n","    \n","    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n","    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n","    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n","    def __getitem__(self, index):\n","        # index는 몇번째 batch인지를 나타냄. \n","        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n","        # 32x32 image array를 self.batch_size만큼 가져옴. \n","        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n","        if self.labels is not None:\n","            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n","        \n","        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n","        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n","        # 변환된 image 배열값을 담을 image_batch 선언. image_batch 배열은 float32 로 설정. \n","        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n","        \n","        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n","        for image_index in range(images_fetch.shape[0]):\n","            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n","            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n","            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n","            # 만약 augmentor가 주어졌다면 이를 적용. \n","            if self.augmentor is not None:\n","                image = self.augmentor(image=image)['image']\n","                \n","            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n","            if self.pre_func is not None:\n","                image = self.pre_func(image)\n","            \n","            # image_batch에 순차적으로 변환된 image를 담음.               \n","            image_batch[image_index] = image\n","        \n","        return image_batch, label_batch\n","    \n","    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n","    def on_epoch_end(self):\n","        if(self.shuffle):\n","            #print('epoch end')\n","            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n","            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n","        else:\n","            pass"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:16.612162Z","iopub.status.busy":"2022-09-28T07:10:16.611764Z","iopub.status.idle":"2022-09-28T07:10:22.573997Z","shell.execute_reply":"2022-09-28T07:10:22.570974Z","shell.execute_reply.started":"2022-09-28T07:10:16.612111Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","170508288/170498071 [==============================] - 4s 0us/step\n","(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","(40000, 32, 32, 3) (40000, 10) (10000, 32, 32, 3) (10000, 10) (10000, 32, 32, 3) (10000, 10)\n"]}],"source":["# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n","\n","(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.2, random_state=2021)\n","print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:10:22.576942Z","iopub.status.busy":"2022-09-28T07:10:22.576046Z","iopub.status.idle":"2022-09-28T07:10:22.708983Z","shell.execute_reply":"2022-09-28T07:10:22.707944Z","shell.execute_reply.started":"2022-09-28T07:10:22.576874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 128, 128, 3) (64, 128, 128, 3)\n","(64, 10) (64, 10)\n","[[[ 73.061     57.221     40.32    ]\n","  [ 73.061     57.221     40.32    ]\n","  [ 70.061     54.221     38.32    ]\n","  ...\n","  [-34.939003 -42.779    -50.68    ]\n","  [-35.939003 -44.779    -53.68    ]\n","  [-35.939003 -44.779    -53.68    ]]\n","\n"," [[ 73.061     57.221     40.32    ]\n","  [ 73.061     57.221     40.32    ]\n","  [ 70.061     54.221     38.32    ]\n","  ...\n","  [-34.939003 -42.779    -50.68    ]\n","  [-35.939003 -44.779    -53.68    ]\n","  [-35.939003 -44.779    -53.68    ]]\n","\n"," [[ 75.061     59.221     42.32    ]\n","  [ 75.061     59.221     42.32    ]\n","  [ 72.061     56.221     40.32    ]\n","  ...\n","  [-34.939003 -42.779    -50.68    ]\n","  [-35.939003 -44.779    -52.68    ]\n","  [-35.939003 -44.779    -52.68    ]]\n","\n"," ...\n","\n"," [[120.061    102.221    109.32    ]\n","  [120.061    102.221    109.32    ]\n","  [116.061     99.221    107.32    ]\n","  ...\n","  [-35.939003 -44.779    -55.68    ]\n","  [-34.939003 -43.779    -53.68    ]\n","  [-34.939003 -43.779    -53.68    ]]\n","\n"," [[121.061    103.221    110.32    ]\n","  [121.061    103.221    110.32    ]\n","  [117.061    100.221    107.32    ]\n","  ...\n","  [-36.939003 -45.779    -56.68    ]\n","  [-35.939003 -44.779    -54.68    ]\n","  [-35.939003 -44.779    -54.68    ]]\n","\n"," [[121.061    103.221    110.32    ]\n","  [121.061    103.221    110.32    ]\n","  [117.061    100.221    107.32    ]\n","  ...\n","  [-36.939003 -45.779    -55.68    ]\n","  [-35.939003 -44.779    -54.68    ]\n","  [-35.939003 -44.779    -54.68    ]]]\n"]}],"source":["from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n","\n","tr_ds = CIFAR_Dataset(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=vgg_preprocess)\n","val_ds = CIFAR_Dataset(val_images, val_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=vgg_preprocess)\n","\n","print(next(iter(tr_ds))[0].shape, next(iter(val_ds))[0].shape)\n","print(next(iter(tr_ds))[1].shape, next(iter(val_ds))[1].shape)\n","# 채널별 값 - mean = [103.939, 116.779, 123.68]\n","print(next(iter(tr_ds))[0][0])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T07:51:30.408581Z","iopub.status.busy":"2022-09-28T07:51:30.408230Z","iopub.status.idle":"2022-09-28T08:17:01.557890Z","shell.execute_reply":"2022-09-28T08:17:01.556972Z","shell.execute_reply.started":"2022-09-28T07:51:30.408549Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg_by_block\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input Tensor (InputLayer)    [(None, 128, 128, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d_3 ( (None, 512)               0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 120)               61560     \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 120)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                1210      \n","=================================================================\n","Total params: 14,777,458\n","Trainable params: 14,777,458\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","625/625 [==============================] - 91s 144ms/step - loss: 1.9481 - accuracy: 0.2574 - val_loss: 1.6181 - val_accuracy: 0.4114\n","Epoch 2/30\n","625/625 [==============================] - 90s 144ms/step - loss: 1.5004 - accuracy: 0.4409 - val_loss: 1.2491 - val_accuracy: 0.5590\n","Epoch 3/30\n","625/625 [==============================] - 90s 144ms/step - loss: 1.1793 - accuracy: 0.5819 - val_loss: 0.9367 - val_accuracy: 0.6686\n","Epoch 4/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.9497 - accuracy: 0.6708 - val_loss: 0.8641 - val_accuracy: 0.6987\n","Epoch 5/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.7653 - accuracy: 0.7434 - val_loss: 0.6741 - val_accuracy: 0.7761\n","Epoch 6/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.6324 - accuracy: 0.7906 - val_loss: 0.5870 - val_accuracy: 0.8048\n","Epoch 7/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.5098 - accuracy: 0.8336 - val_loss: 0.5404 - val_accuracy: 0.8205\n","Epoch 8/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.4102 - accuracy: 0.8661 - val_loss: 0.6106 - val_accuracy: 0.8104\n","Epoch 9/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.3256 - accuracy: 0.8959 - val_loss: 0.5846 - val_accuracy: 0.8266\n","Epoch 10/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.2556 - accuracy: 0.9175 - val_loss: 0.6095 - val_accuracy: 0.8241\n","Epoch 11/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.2021 - accuracy: 0.9345 - val_loss: 0.6247 - val_accuracy: 0.8291\n","Epoch 12/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.1559 - accuracy: 0.9523 - val_loss: 0.5911 - val_accuracy: 0.8402\n","\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","Epoch 13/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 0.6955 - val_accuracy: 0.8535\n","Epoch 14/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.8104 - val_accuracy: 0.8526\n","Epoch 15/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.8466 - val_accuracy: 0.8564\n","Epoch 16/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.8975 - val_accuracy: 0.8555\n","Epoch 17/30\n","625/625 [==============================] - 90s 144ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.9929 - val_accuracy: 0.8554\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n","Epoch 00017: early stopping\n"]}],"source":["vgg_model = create_vggnet_by_block(in_shape=(128, 128, 3), n_classes=10)\n","\n","vgg_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n","rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n","ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n","\n","history = vgg_model.fit(tr_ds, epochs=30, \n","                    #steps_per_epoch=int(np.ceil(tr_images.shape[0]/BATCH_SIZE)),\n","                    validation_data=val_ds, \n","                    #validation_steps=int(np.ceil(val_images.shape[0]/BATCH_SIZE)), \n","                    callbacks=[rlr_cb, ely_cb]\n","                   )"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T08:17:01.561403Z","iopub.status.busy":"2022-09-28T08:17:01.560418Z","iopub.status.idle":"2022-09-28T08:17:08.255249Z","shell.execute_reply":"2022-09-28T08:17:08.254389Z","shell.execute_reply.started":"2022-09-28T08:17:01.561362Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["157/157 [==============================] - 7s 42ms/step - loss: 1.0488 - accuracy: 0.8443\n"]},{"data":{"text/plain":["[1.0487804412841797, 0.8442999720573425]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=vgg_preprocess)\n","vgg_model.evaluate(test_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"}}},"nbformat":4,"nbformat_minor":4}
